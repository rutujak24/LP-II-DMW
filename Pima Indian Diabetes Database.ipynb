{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R3oQIpu2fwuU"
   },
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "executionInfo": {
     "elapsed": 1459,
     "status": "ok",
     "timestamp": 1606914732337,
     "user": {
      "displayName": "Sachin Johnson Chirayath",
      "photoUrl": "",
      "userId": "18152493364802325657"
     },
     "user_tz": -330
    },
    "id": "JHMe54utfwuW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S-kGfOc9fwuX"
   },
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1802,
     "status": "ok",
     "timestamp": 1606914667740,
     "user": {
      "displayName": "Sachin Johnson Chirayath",
      "photoUrl": "",
      "userId": "18152493364802325657"
     },
     "user_tz": -330
    },
    "id": "WNTjHBwpkKun",
    "outputId": "a8fb6fec-d711-4233-966e-ce1631c3bd54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " output.html  'Pima Indian Diabetes Database.ipynb'\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "executionInfo": {
     "elapsed": 1407,
     "status": "error",
     "timestamp": 1606914736339,
     "user": {
      "displayName": "Sachin Johnson Chirayath",
      "photoUrl": "",
      "userId": "18152493364802325657"
     },
     "user_tz": -330
    },
    "id": "HlFDGuEtfwuX",
    "outputId": "dd2c24e2-61e8-46c3-93a2-ef64ab25f494"
   },
   "outputs": [],
   "source": [
    "\n",
    "url = \"https://raw.githubusercontent.com/VishwajeetEkal/LP-II-Mini-Project/main/diabetes.csv\"\n",
    "dataset = pd.read_csv(url)\n",
    "\n",
    "diabetes = dataset\n",
    "\n",
    "\n",
    "#EDA using Pandas Profiling\n",
    "# file = ProfileReport(dataset)\n",
    "# file.to_file(output_file='output.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing the zero-values for Blood Pressure\n",
    "df1 = dataset.loc[dataset['Outcome'] == 1]\n",
    "df2 = dataset.loc[dataset['Outcome'] == 0]\n",
    "\n",
    "df1 = df1.replace({'BloodPressure':0}, np.median(df1['BloodPressure']))\n",
    "df2 = df2.replace({'BloodPressure':0}, np.median(df2['BloodPressure']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing the zero-values for BMI\n",
    "df1 = df1.replace({'BMI':0}, np.median(df1['BMI']))\n",
    "df2 = df2.replace({'BMI':0}, np.median(df2['BMI']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing the zero-values for Insulin\n",
    "df1 = df1.replace({'Insulin':0}, np.median(df1['Insulin']))\n",
    "df2 = df2.replace({'Insulin':0}, np.median(df2['Insulin']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing the zero-values for SkinThickness\n",
    "df1 = df1.replace({'SkinThickness':0}, np.median(df1['SkinThickness']))\n",
    "df2 = df2.replace({'SkinThickness':0}, np.median(df2['SkinThickness']))\n",
    "\n",
    "dataframe = [df1, df2]\n",
    "dataset = pd.concat(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A57CBWgpfwuZ"
   },
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "id": "44RP1Bn6fwuZ"
   },
   "outputs": [],
   "source": [
    "y = dataset.Outcome\n",
    "x = dataset.drop('Outcome', axis = 1)\n",
    "columns = x.columns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(x)\n",
    "\n",
    "data_x = pd.DataFrame(X, columns = columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5QYuScufwua"
   },
   "source": [
    "## Splitting the dataset into the Training set and Test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "id": "uc8DIfMLfwua"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_x, y, test_size = 0.15, random_state = 45)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([430, 430])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smt = SMOTE()\n",
    "\n",
    "X_train, y_train = smt.fit_sample(X_train, y_train)\n",
    "\n",
    "np.bincount(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0tjARtxHfwua"
   },
   "source": [
    "## Training the Naive Bayes model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "id": "pvgsLB4Dfwub",
    "outputId": "4c6007a7-42ca-40fe-d8f5-d78f47c9a89a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0DDXJeiLfwub"
   },
   "source": [
    "## Predicting the Test set Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "id": "Y6CvECOgfwub"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of NB classifier on test set: 0.74\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "print('Accuracy of NB classifier on test set: {:.2f}'.format(classifier.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RDEkLcDefwub"
   },
   "source": [
    "## Making the Confusion Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "id": "HowJcibXfwub",
    "outputId": "77c03f57-59f2-4204-aad3-c8eb176a7697"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[54 16]\n",
      " [14 32]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7317298797409806\n",
      "0.7303921568627451\n",
      "0.7335403726708074\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "print(metrics.f1_score(y_test, y_pred, average=\"macro\"))\n",
    "print(metrics.precision_score(y_test, y_pred, average=\"macro\"))\n",
    "print(metrics.recall_score(y_test, y_pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8gn7upK0fwub"
   },
   "source": [
    "## Training the K-NN model on the Training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "id": "g5p0o0YTfwub",
    "outputId": "27841a8f-2ab8-4d0d-e76a-8ad469fcd6d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iD0VFeqLfwuc"
   },
   "source": [
    "## Predicting the Test set Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "id": "RQ1_i9qkfwuc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of K-NN model on test set: 0.74\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "print('Accuracy of K-NN model on test set: {:.2f}'.format(classifier.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3lz3DedRfwuc"
   },
   "source": [
    "## Making the Confusion Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "id": "iuoae-O5fwuc",
    "outputId": "f8b1970f-1252-46e3-c01d-01ee562662a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[54 16]\n",
      " [14 32]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7317298797409806\n",
      "0.7303921568627451\n",
      "0.7335403726708074\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "print(metrics.f1_score(y_test, y_pred, average=\"macro\"))\n",
    "print(metrics.precision_score(y_test, y_pred, average=\"macro\"))\n",
    "print(metrics.recall_score(y_test, y_pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f_zORNiEfwuc"
   },
   "source": [
    "## Training the SVM model on the Training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "id": "hZZLQhpTfwud",
    "outputId": "a70725f4-b6ed-4259-fc39-dacf9260b2cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', random_state=0)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vEsY0_hWfwud"
   },
   "source": [
    "## Predicting the Test set Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "id": "MfeBtS8Tfwud"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM(linear) model on test set: 0.73\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "print('Accuracy of SVM(linear) model on test set: {:.2f}'.format(classifier.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yCzbbJ1qfwud"
   },
   "source": [
    "## Making the Confusion Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "id": "QjqxffQrfwud",
    "outputId": "7bb0ae11-19eb-415b-ffab-80e1961c9fe7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[52 18]\n",
      " [13 33]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7253913707521955\n",
      "0.723529411764706\n",
      "0.7301242236024845\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "print(metrics.f1_score(y_test, y_pred, average=\"macro\"))\n",
    "print(metrics.precision_score(y_test, y_pred, average=\"macro\"))\n",
    "print(metrics.recall_score(y_test, y_pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Random Forest Classifer on Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features='sqrt', n_estimators=300)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators=300, bootstrap = True, max_features = 'sqrt')\n",
    "classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Test Set Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest on test set: 0.84\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "print('Accuracy of Random Forest on test set: {:.2f}'.format(classifier.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[63  7]\n",
      " [11 35]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8352272727272727\n",
      "0.8423423423423424\n",
      "0.8304347826086957\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "print(metrics.f1_score(y_test, y_pred, average=\"macro\"))\n",
    "print(metrics.precision_score(y_test, y_pred, average=\"macro\"))\n",
    "print(metrics.recall_score(y_test, y_pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Pima Indian Diabetes Database.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
